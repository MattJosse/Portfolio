Here is my first ever Neural Network training ! 

We studied Word2Vec : the goal was to produce a dataset of 300-dim vectors, representing words and their meanings.

We used clever singular value decmoposition to represent those 300-dim vectors in a 2 dim plan, in the file "word_vectors.png".
We are pretty happy with result. As an exemple, you can see that "tea" and "coffee" are really close, as are "amazing" and "wondefull". Moreover, the vector going from "male" to "female" is the as than the one going from "king" to "queen" !In other words, we managed to encode the meaning of masculine and feminine into our model.
However, it could have been assumed that "man" was close to "male".


In fact, our work was a little more complicated than training a neural network, because we had to train both the model and the dataset


I achieved this work with my wonderfull teammates : Hangao Liang, Wembo Duan, Dung Le Quang, and Malo Aymes.
